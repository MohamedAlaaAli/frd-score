"""Calculates the Frechet Radiomics Distance (FRD) to compare image biomarker distributions

The FRD metric calculates the distance between two distributions of biomarkers extracted from imaging data.
Typically, one of the two distributions is generated by a generative feature_extractor such as GANs or Diffusion feature_extractors.
When run as a stand-alone program, it compares the distribution of images that are stored as PNG/JPEG/NIfTI at
a specified location.

Some code from https://github.com/mseitzer/pytorch-fid and https://github.com/bioinf-jku/TTUR was reused and adapted.

Usage:
    python frd.py dir1 dir2

"""

import argparse
import csv
import logging
import os
import pathlib
import time
from pathlib import Path

import cv2
import numpy as np
import SimpleITK as sitk

from radiomics import featureextractor
from scipy import linalg
from tqdm import tqdm


# Define allowed image extensions
IMAGE_EXTENSIONS = {
    "bmp",
    "jpg",
    "jpeg",
    "png",
    "tif",
    "tiff",
    "nii.gz",
}  # 'pgm', 'ppm', 'webp',

# correctMask: Resize mask if there is a size mismatch between image and mask
# minimumROIDimensions: Set the minimum number of dimensions for a ROI mask. Needed to avoid error, as in our datasets we may have some masks with dim=1.
# https://pyradiomics.readthedocs.io/en/latest/radiomics.html#radiomics.imageoperations.checkMask
# force2D: True is needed to extract 2d shape features when 'shape2d' is passed as feature name alongside 3d data
# Future work: Allow users to more easily access and adjust the settings dictionary (e.g. via command line arguments)
RADIOMICS_SETTINGS = {
    "correctMask": True,
    "minimumROIDimensions": 1,
}  # "force2D": True,}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Calculates the Frechet Radiomics Distance between two distributions of extracted pyradiomics "
        "features."
    )
    parser.add_argument(
        "paths",
        type=str,
        nargs=2,
        help="The two paths to the generated images or to .npz statistic files",
    )

    parser.add_argument(
        "-m",
        "--paths_masks",
        type=str,
        nargs=2,
        default=None,
        help="The two paths to the folder where the mask files are located.",
    )

    parser.add_argument(
        "-f",
        "--feature_groups",
        nargs='+',
        type=str,
        default=[
            "firstorder",
            "glcm",
            "glrlm",
            "gldm",
            "glszm",
            "ngtdm",
            "shape",
            "shape2D",
        ],
        help="The pyradiomics feature groups to be used for the frd calculation. Can be 'firstorder', "
        "'glcm', 'glrlm', 'gldm', 'glszm', 'ngtdm', 'shape', 'shape2D' ",
    )

    parser.add_argument(
        "-is_m",
        "--is_mask_used",
        action="store_true",
        help="Generate radiomics based on either available mask or for the whole image.",
    )

    parser.add_argument(
        "-r",
        "--resize_size",
        type=int,
        default=None,
        help="In case the input images (and masks) are to be resized to a specific pixel dimension. "
    )

    parser.add_argument(
        "-s",
        "--save_stats",
        action="store_true",
        help="Generate an npz archive from a directory of samples. The first path is used as input and "
        "the second as output.",
    )

    parser.add_argument(
        "-nr",
        "--normalization_range",
        nargs=2,
        type=float,
        default=[0., 7.45670747756958],
        help="The allowed value range of features. Based on these values the frd features will be "
        "normalized. The range should be [min, max]. Default is [0, 7.45670747756958]. "
        "If normalization_type is 'zscore', we recommend ignoring normalization range by setting "
        "it to [0, 1].",
    )

    parser.add_argument(
        "-nt",
        "--normalization_type",
        type=str,
        default="minmax",
        help="The strategy with which the frd features will be normalized. Can be 'minmax' "
        "or 'zscore'.",
    )

    parser.add_argument(
        "--features",
        type=str,
        default=None,
        help="you may use this option to provide a csv file (e.g., path/to/feature_names.csv) with the feature names to be used for the "
        "frd calculation. The csv file should have a single column with the feature names.",
    )

    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="You may enable more detailed logging (logging.info) console logs by providing the 'verbose' argument.",
    )

    parser.add_argument(
        "-sf",
        "--save_features",
        action="store_true",
        help="Indicates whether radiomics feature values (normalized and non-normalized) should be stored in a csv file. "
        "This can be useful for reproducibility and interpretability.",
    )

    args = parser.parse_args()
    return args


def get_activations(
    files,
    feature_extractor,
    is_mask_used=True,
    masks=None,
    resize_size=None,
    verbose=False,
):
    """Calculates the activations of the pool_3 layer for all images.

    Params:
    -- files       : List of image files paths
    -- feature_extractor       : Instance of radiomics feature_extractor
    -- is_mask_used : Boolean indicating whether masks should be used for feature extraction
    -- masks : The list of paths of the mask files
    -- resize_size: In case the images should be resized before the radiomics features are calculated
    -- verbose: Indicates the verbosity level of the logging. If true, more info is logged to console.

    Returns:
    -- A numpy array of dimension (num images, num_features) that contains the
       extracted features of the given query image (optionally, alongside a respective segmentation mask).
    """

    image_paths = []
    mask_paths = []
    radiomics_results = []

    for idx, file_path in enumerate(files):
        if masks is not None:
            image_paths.append(file_path)
            if not is_mask_used:
                mask_paths.append(None)
            else:
                # Note: Sorting assumption here: Masks and images are in separate folders. Each image has a mask and
                # mask and image file are named similarly enough that sorting assures correspondence between image and mask index positions.
                try:
                    mask_paths.append(masks[idx])
                except IndexError as e:
                    raise RuntimeError(
                        f"Mask '{idx}' not found for image file '{file_path}'. "
                        f"Please revise that for each image there is a mask present. "
                        f"Ensure file names of image and mask correspond, as index position "
                        f"correspondence is assumed after sorting both image and mask lists. "
                        f"Exception: {e}"
                    )

        # elif "_mask" in str(file_path) or str(file_path).endswith("_mask.png") or str(file_path).endswith(
        #        "_mask_synth.jpg"):
        #    mask_paths.append(file_path)
        else:
            image_paths.append(file_path)
            mask_paths.append(None)

    total = len(image_paths)

    with tqdm(total=total) as pbar:
        for i, (image_path, mask_path) in enumerate(zip(image_paths, mask_paths)):
            sitk_image = sitk.ReadImage(str(image_path), outputPixelType=sitk.sitkFloat32)
            if mask_path is None:
                # https://discourse.slicer.org/t/features-extraction/11047/3
                ma_arr = np.ones(sitk_image.GetSize()[::-1]).astype(
                    np.uint8
                )  # reverse the order as image is xyz, array is zyx
                sitk_mask = sitk.GetImageFromArray(ma_arr)
                try:
                    sitk_mask.CopyInformation(sitk_image)  # Copy geometric info
                except Exception as e:
                    logging.debug(
                        f"Error while trying to copy information from image to mask: {e}"
                    )
                    pass
                if verbose:
                    logging.debug(
                        "Empty mask (true everywhere) is used for feature extraction."
                    )
            else:
                sitk_mask = sitk.ReadImage(str(mask_path))

            # Check if the mask is in range [0, 255] and rescale it to [0, 1]
            if np.max(sitk.GetArrayFromImage(sitk_mask)) == 255:
                sitk_mask = sitk.Cast(sitk_mask, sitk.sitkFloat32) / 255.0

            if verbose and i % 100 == 0:
                # get some logging.infos to check the progress and if everything is working
                logging.info(
                    f"Now processing corresponding image-mask pair (IMG:{image_path}, MASK: {mask_path}. Do these correspond?"
                )

            if resize_size is not None:
                sitk_image_array = sitk.GetArrayFromImage(sitk_image)
                sitk_image_array_resized = resize_image_array(
                    sitk_image_array, resize_size, interpolation=cv2.INTER_LINEAR
                )
                sitk_image_resized = sitk.GetImageFromArray(sitk_image_array_resized)
                try:
                    sitk_image_resized.CopyInformation(sitk_image)
                except:
                    pass
                sitk_image = sitk_image_resized  # Update the image to the resized version

                sitk_mask_array = sitk.GetArrayFromImage(sitk_mask)
                sitk_mask_array_resized = resize_image_array(
                    sitk_mask_array, resize_size, interpolation=cv2.INTER_LINEAR
                )
                # After resizing, set all values above 0.5 to 1 and all values below to 0
                sitk_mask_array_resized[sitk_mask_array_resized > 0.5] = 1
                sitk_mask_array_resized[sitk_mask_array_resized <= 0.5] = 0
                sitk_mask_resized = sitk.GetImageFromArray(sitk_mask_array_resized)
                try:
                    sitk_mask_resized.CopyInformation(sitk_mask)
                except:
                    pass
                sitk_mask = sitk_mask_resized

            # Check if the mask contains only one voxel. This needs to be done before and after resizing as the mask
            if np.sum(sitk.GetArrayFromImage(sitk_mask)) <= 1:
                if verbose:
                    logging.info(
                        f"Skipping mask (after potentially having applied resizing to {resize_size}) with only one segmented voxel:",
                        mask_path,
                    )
                continue

            # Finally, run the feature extraction
            try:
                output = feature_extractor.execute(sitk_image, sitk_mask)
            except Exception as e:
                logging.debug(f"sitk_mask: {(sitk.GetArrayFromImage(sitk_mask))}")
                logging.debug(f"sitk_image: {(sitk.GetArrayFromImage(sitk_image))}")
                logging.debug(
                    f"shape sitk_mask: {(sitk.GetArrayFromImage(sitk_mask)).shape} and shape sitk_image: {(sitk.GetArrayFromImage(sitk_image)).shape}"
                )
                logging.error(
                    f"Error occurred while extracting features for image {i} from image {image_path} and mask {mask_path}: {e}"
                )
                raise e
            radiomics_features = {}
            for feature_name in output.keys():
                if "diagnostics" not in feature_name:
                    radiomics_features[feature_name.replace("original_", "")] = float(
                        output[feature_name]
                    )
            radiomics_results.append(radiomics_features)
            if verbose:
                logging.debug(
                    f"img_shape:{sitk.GetArrayFromImage(sitk_image).shape}, features: {len(list(radiomics_features.values()))}"
                )

            try:
                # We check if pred_arr is defined already.
                pred_arr
            except NameError:
                # As pred_arr was not yet defined we initialize it here based on the length/dimensionality of radiomics features
                pred_arr = np.empty(
                    (len(image_paths), len(list(radiomics_features.values())))
                )

            pred_arr[i] = list(radiomics_features.values())
            if verbose:
                logging.debug(
                    f"Total number of features extracted for image {i}: {len(pred_arr[i])}"
                )
            pbar.update(1)

    if radiomics_results:
        sample_dict = radiomics_results[0]
        num_features = len(sample_dict)
        if verbose:
            logging.info(f"Number of radiomics features: {num_features}")

    return pred_arr, radiomics_results, image_paths, mask_paths


def resize_image_array(sitk_image_array, resize_size, interpolation=cv2.INTER_LINEAR):
    if len(sitk_image_array.shape) == 2:
        sitk_image_array_resized = cv2.resize(
            sitk_image_array, (resize_size, resize_size), interpolation=interpolation
        )
    elif len(sitk_image_array.shape) == 3:
        # Going through z axis (which should be at index position 0 here in sitk image, and resizing each slice
        sitk_image_array_resized = np.zeros(
            (sitk_image_array.shape[0], resize_size, resize_size)
        )
        for j in range(sitk_image_array.shape[0]):
            sitk_image_array_resized[j] = cv2.resize(
                sitk_image_array[j],
                (resize_size, resize_size),
                interpolation=interpolation,
            )
    else:
        raise ValueError(
            f"SITK Image array has an unexpected shape: {sitk_image_array.shape}. Expected 2D or 3D array (no channel dim). Got {len(sitk_image_array.shape)}"
        )
    return sitk_image_array_resized


def save_features_to_csv(csv_file_path, image_paths, mask_paths, feature_data):
    """Save the feature data to a CSV file.

    Params:
    -- csv_file_path   : Path to the CSV file where the results will be saved
    -- image_paths     : List of image file paths. NOTE: Normally, the parent folder of this folder is where the csv features will be saved
    -- mask_paths      : List of mask file paths
    -- feature_data    : Feature data to be saved in the CSV file
    """

    with open(csv_file_path, "w", newline="") as csv_file:
        writer = csv.writer(csv_file)

        # Write the header row
        header = ["image_path", "mask_path"]
        for feature_name in feature_data[0].keys():
            header.append(feature_name)
        writer.writerow(header)

        # Write the rows for each image
        for image_path, mask_path, features in zip(
            image_paths, mask_paths, feature_data
        ):
            # if mask_path is not None:
            #    mask_path = mask_path.with_name(mask_path.name.replace("_img_synth.jpg", "_mask_synth.jpg"))
            row = [str(image_path), str(mask_path)]
            row.extend(features.values())
            writer.writerow(row)

        # Compute and save the min and max values for each column
        num_features = len(feature_data[0])
        min_values = [
            np.min([data[feature_name] for data in feature_data])
            for feature_name in feature_data[0].keys()
        ]
        max_values = [
            np.max([data[feature_name] for data in feature_data])
            for feature_name in feature_data[0].keys()
        ]
        empty_row = [""] * (
            num_features + 2
        )  # Create an empty row to separate the data

        # Write the rows for min values
        writer.writerow(empty_row)
        writer.writerow(["Min", ""] + min_values)

        # Write the rows for max values
        writer.writerow(empty_row)
        writer.writerow(["Max", ""] + max_values)
    logging.info(f"Feature data saved to {csv_file_path}.")


def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):
    """Numpy implementation of the Frechet Distance.
    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)
    and X_2 ~ N(mu_2, C_2) is
            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).

    Stable version by Dougal J. Sutherland.

    Params:
    -- mu1   : Numpy array containing the features of the first set of samples.
    -- mu2   : Numpy array containing the features of the second set of samples.
    -- sigma1: The covariance matrix over activations for the first set of samples.
    -- sigma2: The covariance matrix over activations for the second set of samples.

    Returns:
    --   : The Frechet Distance.
    """

    mu1 = np.atleast_1d(mu1)
    mu2 = np.atleast_1d(mu2)

    sigma1 = np.atleast_2d(sigma1)
    sigma2 = np.atleast_2d(sigma2)

    assert (
        mu1.shape == mu2.shape
    ), "Training and test mean vectors have different lengths"
    assert (
        sigma1.shape == sigma2.shape
    ), "Training and test covariances have different dimensions"

    diff = mu1 - mu2

    # Product might be almost singular
    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)
    if not np.isfinite(covmean).all():
        msg = (
            "fid calculation produces singular product; "
            "adding %s to diagonal of cov estimates"
        ) % eps
        logging.debug(msg)
        offset = np.eye(sigma1.shape[0]) * eps
        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))

    # Numerical error might give slight imaginary component
    if np.iscomplexobj(covmean):
        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):
            m = np.max(np.abs(covmean.imag))
            # raise ValueError('Imaginary component {}'.format(m))
        covmean = covmean.real

    tr_covmean = np.trace(covmean)

    return diff.dot(diff) + np.trace(sigma1) + np.trace(sigma2) - 2 * tr_covmean


def z_score_normalize(
    features, new_min=0, new_max=1, replace_nan=True, strict=False, feature_names=None
):
    """Calculate the z score normalisation values of each feature across all images"""

    mean_values = np.nanmean(features, axis=0)
    std_values = np.nanstd(features, axis=0)

    # Create a new copy of features to perform normalization
    normalized_features = np.copy(features)

    # Perform z-score normalization for columns with different mean and std values
    for idx, (mean_val, std_val) in enumerate(zip(mean_values, std_values)):
        if not np.isnan(mean_val) and not np.isnan(std_val):
            feature_name = (
                feature_names[idx] if feature_names is not None else f"feature_{idx}"
            )
            # first we calculate the z-score, and then we normalize it to the new range
            # Note: We decided against shifting the distribution mean and std like in https://math.stackexchange.com/a/2908415
            # The reason for this is that we do not know the target mean, as we only have the target min and max
            # Also, we prefer not to change the std to avoid losing information and artificially removing/adding variation to the final FRD score
            # For this reason we stick to min-max normalization based on the z-score standardised values.
            # The downside is that the z-score values are not in the range between 0 and 1, so resulting values can be
            # lower than new_min and larger than new_max. This can increase the variation thereby affecting the FRD score.
            # For this reason we recommend (as a default), to use minmax instead of z-score normalization in FRD.
            logging.debug(
                f"{feature_name} std_val: {std_val}, mean_val: {mean_val}"
            )  # watch out as std can be very low or 0
            if std_val == 0 and strict:
                raise ValueError(
                    f"Warning: While calculating z-score (idx={idx}), a standard deviation of 0 was detected for feature {feature_name} (mean: {mean_val}). Please check the data for constant values. "
                    f"You may set normalization_type to 'minmax' to avoid this issue."
                )
            if std_val == 0:
                logging.warning(
                    f"Warning: While calculating z-score (idx={idx}), a standard deviation of 0 was detected for feature {feature_name} (mean: {mean_val}). Fallback: Now replacing these feature values with 0 + new_min. new_min={new_min}. "
                    f"Alternatively, you may run again by setting normalization_type to 'minmax' to avoid this issue."
                )
                normalized_features[:, idx] = 0 + float(new_min)
            else:
                normalized_features[:, idx] = (
                    (features[:, idx] - mean_val) / std_val
                ) * (float(new_max) - float(new_min)) + float(new_min)
            logging.debug(
                f"initial features: {features[:, idx]}. Their z-scores: {normalized_features[:, idx]}. Feature names: {feature_names}."
            )

    if replace_nan:
        # Replace NaN values with the mean of new_min and new_max
        nan_indices = np.isnan(normalized_features)
        mean_value = (float(new_min) + float(new_max)) / 2
        normalized_features[nan_indices] = mean_value

    return normalized_features


def min_max_normalize(features, new_min, new_max, replace_nan=True, feature_names=None):
    """Calculate the minimum and maximum values of each feature across all images"""

    min_values = np.nanmin(features, axis=0)
    max_values = np.nanmax(features, axis=0)

    # Create a new copy of features to perform normalization
    normalized_features = np.copy(features)

    # Perform Min-Max normalization for columns with different min and max values
    for idx, (min_val, max_val) in enumerate(zip(min_values, max_values)):
        if not np.isnan(min_val) and not np.isnan(max_val):
            if (max_val - min_val) == 0:
                feature_name = (
                    feature_names[idx]
                    if feature_names is not None
                    else f"feature_{idx}"
                )
                logging.warning(
                    f"Warning: While calculating minmax value (idx={idx}), a max_val - min_val ({max_val}-{min_val}) "
                    f"resulted in 0 for feature {feature_name} . Fallback: Now replacing feature value with 0.5 "
                    f"before scaling to new range ({float(new_min)}, {float(new_max)})."
                )
                normalized_features[:, idx] = 0.5 * (
                    float(new_max) - float(new_min)
                ) + float(new_min)
            else:
                normalized_features[:, idx] = (
                    (features[:, idx] - min_val) / (max_val - min_val)
                ) * (float(new_max) - float(new_min)) + float(new_min)

    if replace_nan:
        # Replace NaN values with the mean of new_min and new_max
        nan_indices = np.isnan(normalized_features)
        mean_value = (new_min + new_max) / 2
        normalized_features[nan_indices] = mean_value

    logging.debug(
        f"initial features: {features[:, idx]}. minmax standardized features: {normalized_features[:, idx]}. Feature names: {feature_names}."
    )

    return normalized_features


def calculate_activation_statistics(
    files,
    normalization_type,
    normalization_range,
    feature_extractor,
    is_mask_used=True,
    masks=None,
    resize_size=None,
    verbose=False,
    save_features=False,
):
    """Calculation of the statistics used by the FID.
    Params:
    -- files                : List of image files paths
    -- normalization_type : The method with which the extracted features should be normalized
    -- normalization_range : The range of normalization to scale the extracted features to after normalization
    -- feature_extractor    : Instance of pyradiomics feature_extractor
    -- is_mask_used : Boolean indicating whether masks should be used for feature extraction
    -- masks : The list of paths of the mask files
    -- resize_size: In case the images should be resized before the radiomics features are calculated
    -- verbose: Indicates the verbosity level of the logging. If true, more info is logged to console.

    Returns:
    -- mu    : The mean over features extracted by the pyradiomics feature_extractor.
    -- sigma : The covariance matrix of the features extracted by the pyradiomics feature_extractor.
    """
    act, radiomics_results, image_paths, mask_paths = get_activations(
        files=files,
        feature_extractor=feature_extractor,
        is_mask_used=is_mask_used,
        masks=masks,
        resize_size=resize_size,
        verbose=verbose,
    )
    if verbose:
        logging.debug(f"features of radiomics: {act}")
        logging.debug(f"features of radiomics shape: {type(act)}")

    # Extract the folder name from the first image file path
    folder_name = Path(files[0]).parent.stem

    # Generate a unique identifier using the current timestamp
    unique_identifier = int(time.time())

    # Define the CSV file path with a unique identifier and the folder name in the name. Default: Store inside parent folder of image_paths
    csv_file_path = os.path.join(
        str(Path(files[0]).parents[1]),
        f"radiomics_results_{folder_name}_{unique_identifier}.csv",
    )

    # to check NaN values in features
    features = act

    if np.isnan(features).any():
        nan_indices = np.where(np.isnan(features))
        unique_nan_indices = np.unique(nan_indices[1])
        logging.warning("Warning: NaN values detected in the features array.")
        if verbose:
            logging.info("Number of NaN values for each feature:")
        for feature_idx in unique_nan_indices:
            nan_count = np.sum(np.isnan(features[:, feature_idx]))
            if verbose:
                logging.info(f"Feature {feature_idx}: {nan_count} NaN values")
            # Get the row indices with NaN values for this feature
            row_indices_with_nan = nan_indices[0][nan_indices[1] == feature_idx]
            if verbose:
                logging.info(
                    f"Row indices with NaN values for Feature {feature_idx}: {row_indices_with_nan}"
                )

    # get the feature names
    feature_names = list(radiomics_results[0].keys())
    if normalization_type == "minmax":
        normalized_act = min_max_normalize(
            features=act,
            new_min=normalization_range[0],
            new_max=normalization_range[1],
            feature_names=feature_names,
        )
    elif normalization_type == "zscore":
        normalized_act = z_score_normalize(
            features=act,
            new_min=normalization_range[0],
            new_max=normalization_range[1],
            feature_names=feature_names,
        )
    else:
        raise ValueError(
            f"Normalization type {normalization_type} is not supported. "
            f"Please use 'minmax' or 'zscore'."
        )

    if verbose:
        logging.debug(f"features found are as follows: {act}")
        logging.debug(f"normalized_features: {normalized_act}")

    norm_csv_file_path = os.path.join(
        str(Path(files[0]).parents[1]),
        f"radiomics_results_normalized_{folder_name}_{unique_identifier}.csv",
    )
    if save_features:
        save_features_to_csv(csv_file_path, image_paths, mask_paths, radiomics_results)
        save_features_to_csv(
            norm_csv_file_path, image_paths, mask_paths, radiomics_results
        )

    mu = np.mean(normalized_act, axis=0)
    sigma = np.cov(normalized_act, rowvar=False)
    if verbose:
        logging.debug(f"mu and sigma:  {mu} {sigma}")
        logging.info(f"mu and sigma length: {len(mu)}, {len(sigma)}")
    return mu, sigma


def compute_statistics_of_path(
    path,
    normalization_type,
    normalization_range,
    feature_extractor,
    is_mask_used=True,
    path_mask=None,
    resize_size=None,
    verbose=False,
    save_features=False,
):
    """Calculates the statistics later used to compute the Frechet Distance for a given path (i.e. one of the two distributions)."""

    if path.endswith(".npz"):
        with np.load(path) as f:
            m, s = f["mu"][:], f["sigma"][:]
    else:
        path = pathlib.Path(path)
        files = sorted(
            [file for ext in IMAGE_EXTENSIONS for file in path.glob("*.{}".format(ext))]
        )
        if path_mask is not None:
            # Assumption: Each file in image dir has a corresponding file in mask dir with name
            # similar enough to ensure correspondence via sorting
            masks = sorted(
                [
                    mask
                    for ext in IMAGE_EXTENSIONS
                    for mask in path.glob("*.{}".format(ext))
                ]
            )
        else:
            masks = None
            if verbose:
                logging.debug(f"files in compute_statistics_of_path: {files}")
        m, s = calculate_activation_statistics(
            files=files,
            normalization_type=normalization_type,
            normalization_range=normalization_range,
            feature_extractor=feature_extractor,
            is_mask_used=is_mask_used,
            masks=masks,
            resize_size=resize_size,
            verbose=verbose,
            save_features=save_features,
        )
    return m, s


def get_feature_extractor(features, settings_dict: dict = None):
    """Returns a pyradiomics feature extractor allowing to customize the list of radiomics features to compute based on your dataset"""

    # Check if features is a string and a path pointing to a csv file
    if isinstance(features, str) and features.endswith(".csv"):
        # raise a not implemented error to indicate that this feature is not yet implemented
        raise NotImplementedError(
            "Feature extraction based on a csv file is not yet implemented. "
            "Please open an issue on github if you would like us to add this feature:"
            "https://github.com/RichardObi/frd/issues/new/choose."
        )
        # with open(features, 'r') as f:
        #    features = [line.strip() for line in f]

    settings = {}
    if settings_dict is None:
        settings_dict = RADIOMICS_SETTINGS
    settings["setting"] = settings_dict
    # settings["setting"] = {"minimumROIDimensions": 1}

    # Set feature classes to compute
    settings["featureClass"] = {feature: [] for feature in features}
    return featureextractor.RadiomicsFeatureExtractor(settings)


def calculate_frd_given_paths(
    paths,
    features,
    normalization_type,
    normalization_range,
    is_mask_used=True,
    paths_masks=None,
    resize_size=None,
    verbose=False,
    save_features=True,
):
    """Calculates the FRD based on the statistics from the two paths (i.e. the two distributions)"""

    for p in paths:
        if not os.path.exists(p):
            raise RuntimeError(f"Invalid path: {p}")

    feature_extractor = get_feature_extractor(features=features)

    m1, s1 = compute_statistics_of_path(
        paths[0],
        normalization_type,
        normalization_range,
        feature_extractor,
        is_mask_used=is_mask_used,
        path_mask=None if paths_masks is None else paths_masks[0],
        resize_size=resize_size,
        verbose=verbose,
        save_features=save_features,
    )
    if verbose:
        logging.debug(f"m1: {m1}, s1: {s1}")
    m2, s2 = compute_statistics_of_path(
        paths[1],
        normalization_type,
        normalization_range,
        feature_extractor,
        is_mask_used=is_mask_used,
        path_mask=None if paths_masks is None else paths_masks[1],
        resize_size=resize_size,
        verbose=verbose,
        save_features=save_features,
    )
    if verbose:
        logging.debug(f"m2: {m2}, s2: {s2}")
    frd_value = calculate_frechet_distance(m1, s1, m2, s2)

    return frd_value


def save_frd_stats(
    paths,
    features,
    normalization_type: str,
    normalization_range: list,
    is_mask_used=True,
    paths_masks=None,
    resize_size=None,
    verbose=False,
    save_features=True,
):
    """Inits feature extractor creation and subsequent statistics computation and saving for the two distributions."""

    if not os.path.exists(paths[0]):
        raise RuntimeError(
            f"Please use a valid path to imaging data. Currently got invalid path: {paths[0]}"
        )

    if os.path.exists(paths[1]):
        raise RuntimeError(
            f"Please use an output file path to an .npz file that does not yet exists. Currently got output file: {paths[1]}"
        )
    elif not paths[1].endswith(".npz"):
        logging.warning(
            f"Please revise as your provided stats output file path '{paths[1]}' does not have an .npz extension. "
            f"Now continuing with the current path."
        )

    feature_extractor = get_feature_extractor(features=features)

    if verbose:
        logging.info(f"Saving statistics for {paths[0]}")

    m1, s1 = compute_statistics_of_path(
        paths[0],
        normalization_type=normalization_type,
        normalization_range=normalization_range,
        feature_extractor=feature_extractor,
        is_mask_used=is_mask_used,
        path_mask=None if paths_masks is None else paths_masks[0],
        resize_size=resize_size,
        verbose=verbose,
        save_features=save_features,
    )

    np.savez_compressed(paths[1], mu=m1, sigma=s1)


def main():
    args = parse_args()
    verbose = args.verbose
    if verbose:
        logging.info(args)

    if args.features is None:
        # we pass only one feature variable into the subsequent functions either containing a link (type str)
        # to a csv file or a list of feature names (type list)
        features = args.feature_groups
    else:
        features = args.features

    if args.save_stats:
        save_frd_stats(
            args.paths,
            features=features,
            normalization_type=args.normalization_type,
            normalization_range=args.normalization_range,
            is_mask_used=args.is_mask_used,
            paths_masks=args.paths_masks,
            resize_size=args.resize_size,
            verbose=args.verbose,
            save_features=args.save_features,
        )
        return

    frd_value = calculate_frd_given_paths(
        args.paths,
        features=features,
        normalization_type=args.normalization_type,
        normalization_range=args.normalization_range,
        is_mask_used=args.is_mask_used,
        paths_masks=args.paths_masks,
        resize_size=args.resize_size,
        verbose=args.verbose,
        save_features=args.save_features,
    )
    # logging the result
    logging.info(
        f"Fréchet Radiomics Distance: {frd_value}. Based on features: {features} with normalization type: {args.normalization_type} and normalization range: {args.normalization_range}{f', with masks: {args.paths_masks}' if args.is_mask_used else ''}{f', resized to {args.resize_size}' if args.resize_size is not None else ''}."
    )
    print(f"FRD: {frd_value}")


if __name__ == "__main__":
    main()
