{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "f02ff153",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
=======
   "execution_count": 22,
   "id": "f02ff153",
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "from transformers import ViTModel, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
<<<<<<< Updated upstream
    "from scipy.optimize import  differential_evolution\n",
    "from dataclasses import dataclass"
=======
    "import torchvision\n",
    "from scipy.fftpack import dct, idct"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16495f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTEmbedder:\n",
    "    def __init__(self, model_name=\"google/vit-base-patch16-224\", device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        Initialize the Vision Transformer embedder without preprocessing.\n",
    "        Expects input tensors to already be normalized and resized correctly.\n",
    "        \"\"\"\n",
    "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = ViTModel.from_pretrained(model_name).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def get_embeddings(self, images: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Get embeddings for a batch of images.\n",
    "\n",
    "        Args:\n",
    "            images (torch.Tensor): Tensor of shape (B, C, H, W) in float32,\n",
    "                                   already normalized & resized to 224x224.\n",
    "                                   Range should match model's expected input.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Embeddings (batch_size, hidden_dim)\n",
    "        \"\"\"\n",
    "        if images.device != self.device:\n",
    "            images = images.to(self.device)\n",
    "\n",
    "        outputs = self.model(pixel_values=images)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86a32e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderPILDataset(Dataset):\n",
    "    def __init__(self, root_dir, extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "        self.root_dir = root_dir\n",
    "        self.extensions = extensions\n",
    "        self.image_paths = [\n",
    "            os.path.join(root, fname)\n",
    "            for root, _, files in os.walk(root_dir)\n",
    "            for fname in files\n",
    "            if fname.lower().endswith(extensions)\n",
    "        ]\n",
    "        if not self.image_paths:\n",
    "            raise ValueError(f\"No images found in {root_dir} with extensions {extensions}\")\n",
    "\n",
    "        # Resize and overwrite images on disk\n",
    "        for path in self.image_paths:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img = img.resize((224,224), Image.BILINEAR)\n",
    "            img.save(path)  # overwrite on disk\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        img = torch.from_numpy(np.array(img)).permute(2, 0, 1).float()/255.0\n",
    "        return (img, self.image_paths[idx])\n",
    "\n",
    "def get_image_dataloader(root_dir, batch_size=8, num_workers=4, shuffle=False):\n",
    "    dataset = ImageFolderPILDataset(root_dir)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d66d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_image_dataloader(\"datasets/clean/busi\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc155a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "vit = ViTEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec8de00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTModel(\n",
       "  (embeddings): ViTEmbeddings(\n",
       "    (patch_embeddings): ViTPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): ViTEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTLayer(\n",
       "        (attention): ViTSdpaAttention(\n",
       "          (attention): ViTSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (output): ViTSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (pooler): ViTPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce0745c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adv_batch(batch, save_dir=\"datasets/adv_simba/busi\", pth=None):\n",
    "    \"\"\"\n",
    "    Save each tensor in the batch as a .bmp image, keeping numbering across calls.\n",
    "    Assumes images are in [0,1] range (float) or [0,255] (uint8).\n",
    "    \"\"\"\n",
    "\n",
    "    for img, p in zip(batch, pth):\n",
    "        img = img.detach().cpu()\n",
    "\n",
    "        # If image is [C, H, W], convert to [H, W, C]\n",
    "        if img.dim() == 3:\n",
    "            img = img.permute(1, 2, 0)\n",
    "        \n",
    "        # Scale to 0â€“255 and convert to uint8 if needed\n",
    "        if img.dtype != torch.uint8:\n",
    "            img = (img * 255).clamp(0, 255).byte()\n",
    "\n",
    "        img_pil = Image.fromarray(img.numpy())\n",
    "        file_path = os.path.join(save_dir, os.path.basename(p))\n",
    "        img_pil.save(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fgsm_kl_attack(model, x, epsilon, temp=0.5):\n",
    "#     \"\"\"\n",
    "#     FGSM attack to maximize KL divergence between original and adversarial embeddings.\n",
    "    \n",
    "#     Args:\n",
    "#         model: embedding model (outputs [B, D] embeddings or logits).\n",
    "#         x: input tensor [B, ...] with requires_grad=False.\n",
    "#         epsilon: L_inf bound (float).\n",
    "#         temp: temperature scaling for embeddings before KL (float).\n",
    "#     Returns:\n",
    "#         x_adv: adversarial example tensor [B, ...].\n",
    "#     \"\"\"\n",
    "#     # Ensure we work on a copy so the original isn't modified\n",
    "#     x, pth = x\n",
    "#     x_adv = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "#     # Get clean embeddings\n",
    "#     with torch.no_grad():\n",
    "#         emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "    \n",
    "#     # Forward pass for adversarial input\n",
    "#     emb_adv = model.get_embeddings(x_adv)  # [B, D]\n",
    "\n",
    "#     # Apply temperature scaling + softmax so KL is well-defined\n",
    "#     p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "#     q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "#     # KL divergence (maximize)\n",
    "#     loss = F.kl_div(p, q, reduction='batchmean')  # KL(p || q)\n",
    "#     loss = -loss  # negate to maximize KL\n",
    "#     # Backprop to get gradient wrt inputs\n",
    "#     loss.backward()\n",
    "\n",
    "#     # FGSM step: sign of gradient, scaled by epsilon\n",
    "#     x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "\n",
    "#     # Project back to valid range (e.g., [0,1] for images)\n",
    "#     x_adv = torch.clamp(x_adv, 0.0, 1.0).detach()\n",
    "\n",
    "#     save_adv_batch(batch=x_adv, pth=pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< Updated upstream
   "id": "0c23e406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_kl_attack_dct(model, x, epsilon, temp=0.5, save_dir=None):\n",
    "    \"\"\"\n",
    "    FGSM attack to maximize KL divergence between original and adversarial embeddings.\n",
    "    \n",
    "    Args:\n",
    "        model: embedding model (outputs [B, D] embeddings or logits).\n",
    "        x: input tensor [B, ...] with requires_grad=False.\n",
    "        epsilon: L_inf bound (float).\n",
    "        temp: temperature scaling for embeddings before KL (float).\n",
    "    Returns:\n",
    "        x_adv: adversarial example tensor [B, ...].\n",
    "    \"\"\"\n",
    "    # Ensure we work on a copy so the original isn't modified\n",
    "    x, pth = x\n",
    "\n",
    "    # x_adversarial in dct domain\n",
    "    x_adv = dct_2d(x).detach().requires_grad_(True)\n",
    "    x_adv_pixel = idct_2d(x_adv)\n",
    "    \n",
    "    # x_adv in dct --> x_adv in pixel --> kl divergence --> grad \n",
    "\n",
    "    # Get clean embeddings\n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "    \n",
    "    # Forward pass for adversarial input\n",
    "    emb_adv = model.get_embeddings(x_adv_pixel)  # [B, D]\n",
    "\n",
    "    # Apply temperature scaling + softmax so KL is well-defined\n",
    "    p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "    q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "    # KL divergence (maximize)\n",
    "    loss = F.kl_div(p, q, reduction='batchmean')  # KL(p || q)\n",
    "    loss = -loss  # negate to maximize KL\n",
    "    # Backprop to get gradient wrt inputs\n",
    "    loss.backward()\n",
    "\n",
    "    # FGSM step: sign of gradient, scaled by epsilon\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sign()\n",
    "\n",
    "    # Project back to valid range (e.g., [0,1] for images)\n",
    "    x_adv_pixel = torch.clamp(idct_2d(x_adv), 0.0, 1.0).detach()\n",
    "    save_adv_batch(batch=x_adv_pixel, pth=pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a365cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_kl_attack_fourier(model, x, epsilon, temp=0.5, save_dir=None):\n",
    "    \"\"\"\n",
    "    FGSM attack to maximize KL divergence between original and adversarial embeddings.\n",
    "    \n",
    "    Args:\n",
    "        model: embedding model (outputs [B, D] embeddings or logits).\n",
    "        x: input tensor [B, ...] with requires_grad=False.\n",
    "        epsilon: L_inf bound (float).\n",
    "        temp: temperature scaling for embeddings before KL (float).\n",
    "    Returns:\n",
    "        x_adv: adversarial example tensor [B, ...].\n",
    "    \"\"\"\n",
    "    # Ensure we work on a copy so the original isn't modified\n",
    "    x, pth = x\n",
    "\n",
    "    # x_adversarial in fourier domain\n",
    "    x_adv = torch.fft.fft2(x) \n",
    "    x_adv = torch.fft.fftshift(x_adv)\n",
    "    x_adv = x_adv.detach().requires_grad_(True)\n",
    "\n",
    "    x_adv_pixel = torch.fft.ifftshift(x_adv)\n",
    "    x_adv_pixel = torch.fft.ifft2(x_adv_pixel).real\n",
    "\n",
    "    # x_adv in dct --> x_adv in pixel --> kl divergence --> grad \n",
    "\n",
    "    # Get clean embeddings\n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "    \n",
    "    # Forward pass for adversarial input\n",
    "    emb_adv = model.get_embeddings(x_adv_pixel)  # [B, D]\n",
    "\n",
    "    # Apply temperature scaling + softmax so KL is well-defined\n",
    "    p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "    q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "    # KL divergence (maximize)\n",
    "    loss = F.kl_div(p, q, reduction='batchmean')  # KL(p || q)\n",
    "    loss = -loss  # negate to maximize KL\n",
    "    # Backprop to get gradient wrt inputs\n",
    "    loss.backward()\n",
    "\n",
    "    # FGSM step: sign of gradient, scaled by epsilon\n",
    "    x_adv = x_adv + epsilon * x_adv.grad.sgn()\n",
    "\n",
    "    # Project back to valid range (e.g., [0,1] for images)\n",
    "    x_adv_pixel = torch.fft.ifftshift(x_adv)\n",
    "    x_adv_pixel = torch.fft.ifft2(x_adv_pixel).real\n",
    "    x_adv_pixel = torch.clamp(x_adv_pixel, 0.0, 1.0).detach()\n",
    "    save_adv_batch(batch=x_adv_pixel, pth=pth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca87c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_kl_attack(model, x, epsilon, alpha=0.01, steps=40, temp=0.5, save_dir=None):\n",
    "    \n",
    "    x, pth = x\n",
    "    x_adv = dct_2d(x)\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # We need this because x_adv is moved to a new tensor in each iteration and requires_grad = false\n",
    "        # Could be fixed by updating using x_adv.data  not x_adv directly but let's leave it for learning purposes\n",
    "        x_adv.requires_grad_(True) \n",
    "        emb_adv = model.get_embeddings(x_adv) # [B, D]\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "        q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "        # KL divergence (maximize)\n",
    "        loss = F.kl_div(p, q, reduction='batchmean')\n",
    "        loss = -loss\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Update \n",
    "            x_adv = x_adv + alpha * x_adv.grad.sign()\n",
    "            \n",
    "            # Projection \n",
    "            perturbation = torch.clamp(x_adv - x, min=-epsilon, max=epsilon)\n",
    "            x_adv = torch.clamp(x + perturbation, 0.0, 1.0)\n",
    "            \n",
    "            x_adv.grad = None\n",
    "\n",
    "    x_adv = x_adv.detach()\n",
    "    save_adv_batch(batch=x_adv, pth=pth)\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_kl_attack_fourier(model, x, epsilon, alpha=0.01, steps=40, temp=0.5, save_dir=None):\n",
    "    \n",
    "    x, pth = x\n",
    "\n",
    "    x_adv = torch.fft.fft2(x)  # Use fft2 for 2D images\n",
    "    x_adv = torch.fft.fftshift(x_adv)\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "\n",
    "    for _ in range(steps):\n",
    "\n",
    "        x_adv.requires_grad_(True) \n",
    "        x_adv_pixel = torch.fft.ifft2(torch.fft.ifftshift(x_adv)).real  # Use ifft2 for 2D\n",
    "\n",
    "        emb_adv = model.get_embeddings(x_adv_pixel) # [B, D]\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "        q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "        # KL divergence (maximize)\n",
    "        loss = F.kl_div(p, q, reduction='batchmean')\n",
    "        loss = -loss\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Update in frequency domain\n",
    "            x_adv = x_adv + alpha * torch.sgn(x_adv.grad)\n",
    "            \n",
    "            # Project back to valid constraints\n",
    "            x_adv_pixel_new = torch.fft.ifft2(torch.fft.ifftshift(x_adv)).real  # Use ifft2\n",
    "            perturbation = torch.clamp(x_adv_pixel_new - x, min=-epsilon, max=epsilon)\n",
    "            x_adv_pixel_clipped = torch.clamp(x + perturbation, min=0.0, max=1.0)\n",
    "            \n",
    "            # Convert back to frequency domain for next iteration\n",
    "            x_adv = torch.fft.fftshift(torch.fft.fft2(x_adv_pixel_clipped))\n",
    "            \n",
    "        # Clear gradients for next iteration\n",
    "        if x_adv.grad is not None:\n",
    "            x_adv.grad = None\n",
    "\n",
    "    # Convert final result back to pixel domain\n",
    "    x_adv_final = torch.fft.ifft2(torch.fft.ifftshift(x_adv)).real\n",
    "    x_adv_final = x_adv_final.detach()\n",
    "    \n",
    "    save_adv_batch(batch=x_adv_final, pth=pth)  # Save pixel domain result\n",
    "    return x_adv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8057e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_kl_attack_dct(model, x, epsilon, alpha=0.01, steps=40, temp=0.5, save_dir=None):\n",
    "    \n",
    "    x, pth = x\n",
    "\n",
    "    x_adv = dct_2d(x)  # Use dct_2d for 2D images\n",
    "     \n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)  # [B, D]\n",
    "\n",
    "    for _ in range(steps):\n",
    "\n",
    "        x_adv.requires_grad_(True) \n",
    "        x_adv_pixel = idct_2d(x_adv)  # Use idct_2d for 2D\n",
    "\n",
    "        emb_adv = model.get_embeddings(x_adv_pixel) # [B, D]\n",
    "\n",
    "        # Apply temperature scaling\n",
    "        p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "        q = F.softmax(emb_adv / temp, dim=-1)\n",
    "\n",
    "        # KL divergence (maximize)\n",
    "        loss = F.kl_div(p, q, reduction='batchmean')\n",
    "        loss = -loss\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Update in dct domain\n",
    "            x_adv = x_adv + alpha * torch.sgn(x_adv.grad)\n",
    "                \n",
    "            # Project back to valid constraints\n",
    "            x_adv_pixel_new = idct_2d(x_adv)\n",
    "            perturbation = torch.clamp(x_adv_pixel_new - x, min=-epsilon, max=epsilon)\n",
    "            x_adv_pixel_clipped = torch.clamp(x + perturbation, min=0.0, max=1.0)\n",
    "            \n",
    "            # Convert back to dct domain for next iteration\n",
    "            x_adv = dct_2d(x_adv_pixel_clipped)\n",
    "\n",
    "        # Clear gradients for next iteration\n",
    "        if x_adv.grad is not None:\n",
    "            x_adv.grad = None\n",
    "\n",
    "    # Convert final result back to pixel domain\n",
    "    x_adv_final = idct_2d(x_adv)\n",
    "    x_adv_final = x_adv_final.detach()\n",
    "    \n",
    "    save_adv_batch(batch=x_adv_final, pth=pth)  # Save pixel domain result\n",
    "    return x_adv_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038b8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-level function\n",
    "def objective_function(candidate, x, emb_clean, model, temp):\n",
    "    x_adv = x.clone()\n",
    "    for i in range(x.shape[0]):\n",
    "        candidate_i = candidate[i*5:(i+1)*5]\n",
    "        xi, yi = int(candidate_i[0]), int(candidate_i[1])\n",
    "        color = torch.tensor(candidate_i[2:], device=x.device, dtype=x.dtype)\n",
    "        x_adv[i, :, xi, yi] = color\n",
    "\n",
    "    emb_adv = model.get_embeddings(x_adv)\n",
    "    p = F.log_softmax(emb_clean / temp, dim=-1)\n",
    "    q = F.softmax(emb_adv / temp, dim=-1)\n",
    "    return -F.kl_div(p, q, reduction='batchmean').item()\n",
    "\n",
    "\n",
    "def one_pixel_kl_attack(model, x, temp=0.5):\n",
    "    \"\"\"\n",
    "    One-pixel attack to maximize KL divergence between original and adversarial embeddings.\n",
    "    \n",
    "    Args:\n",
    "        model: embedding model (outputs [B, D] embeddings or logits).\n",
    "        x: input tensor [B, ...] with requires_grad=False.\n",
    "        d: number of pixels to perturb (int).\n",
    "        temp: temperature scaling for embeddings before KL (float).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    x, pth = x\n",
    "    with torch.no_grad():\n",
    "        emb_clean = model.get_embeddings(x)\n",
    "\n",
    "    # candidate -> array [x, y, color.R, color.G, color.B] * batch_size\n",
    "    bounds = [(0, 223), (0, 223), (0, 1), (0, 1), (0, 1)] * x.shape[0]\n",
    "\n",
    "    result = differential_evolution(\n",
    "        objective_function, \n",
    "        bounds, \n",
    "        args=(x, emb_clean, model, temp),\n",
    "        maxiter=100, \n",
    "        popsize=50, \n",
    "        tol=1e-5, \n",
    "        workers=-1\n",
    "    )\n",
    "\n",
    "    x_adv = x.clone()\n",
    "    for i in range(x.shape[0]):\n",
    "        candidate_i = result.x[i*5:(i+1)*5]\n",
    "        color = torch.tensor(candidate_i[2:]).view(3, 1, 1).to(x.device)\n",
    "        xi, yi = int(candidate_i[0]), int(candidate_i[1])\n",
    "        x_adv[i, :, xi, yi] = color\n",
    "\n",
    "    save_adv_batch(batch=x_adv, pth=pth)\n",
    "    return x_adv, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
=======
>>>>>>> Stashed changes
   "id": "2eba1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in loader:\n",
    "#     fgsm_kl_attack(model=vit, x=batch, epsilon=4/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ecb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Transform helpers\n",
    "# ------------------------\n",
    "def dct2d(img_np):\n",
    "    return dct(dct(img_np, axis=-1, norm='ortho'), axis=-2, norm='ortho')\n",
    "\n",
    "def idct2d(img_dct):\n",
    "    return idct(idct(img_dct, axis=-1, norm='ortho'), axis=-2, norm='ortho')\n",
    "\n",
    "def fft2d(img_np):\n",
    "    return np.fft.fft2(img_np)\n",
    "\n",
    "def ifft2d(img_fft):\n",
    "    return np.fft.ifft2(img_fft).real  # Real part only\n",
    "\n",
    "def apply_channelwise(x_np, fn):\n",
    "    return np.stack([fn(c) for c in x_np], axis=0)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# KL utilities\n",
    "# ------------------------\n",
    "def compute_kl_from_logits(logits_p, logits_q, T):\n",
    "    \"\"\"\n",
    "    Asymmetric KL(p || q) where:\n",
    "        p_log = log_softmax(logits_p / T)\n",
    "        q_log = log_softmax(logits_q / T)\n",
    "        p_prob = softmax(logits_p / T)\n",
    "    \"\"\"\n",
    "    logits_p_t = torch.as_tensor(logits_p, dtype=torch.float32)\n",
    "    logits_q_t = torch.as_tensor(logits_q, dtype=torch.float32)\n",
    "\n",
    "    p_log = F.log_softmax(logits_p_t / T, dim=-1)\n",
    "    q_log = F.log_softmax(logits_q_t / T, dim=-1)\n",
    "    p_prob = p_log.exp()\n",
    "\n",
    "    kl = (p_prob * (p_log - q_log)).sum().item()\n",
    "    return kl\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# SIMBA Attack\n",
    "# ------------------------\n",
    "def simba_attack(\n",
    "    x_tensor,\n",
    "    model,\n",
    "    num_iters=1000,\n",
    "    epsilon=8/255,\n",
    "    step_size=0.005,\n",
    "    T=1.0,\n",
    "    metric=\"kl\",            # 'l2' or 'kl'\n",
    "    space=\"image\",          # 'image', 'dct', or 'fft'\n",
    "    maximize=True,          # True: increase distance, False: decrease\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    SIMBA-style attack.\n",
    "\n",
    "    Args:\n",
    "        x_tensor: torch.Tensor (C, H, W), in [0,1], already on `device`.\n",
    "        model: callable -> given (B, C, H, W) returns raw logits or embeddings.\n",
    "        metric: 'l2' or 'kl' (KL is asymmetric: KL(p||q)).\n",
    "        space: perturbation space: 'image', 'dct', or 'fft'.\n",
    "    \"\"\"\n",
    "    assert metric in [\"l2\", \"kl\"]\n",
    "    assert space in [\"image\", \"dct\", \"fft\"]\n",
    "    x_tensor, pth = x_tensor\n",
    "    x_np = x_tensor.detach().cpu().numpy().astype(np.float32)\n",
    "    _,C, H, W = x_np.shape\n",
    "\n",
    "    # Space transforms\n",
    "    if space == \"image\":\n",
    "        to_space = lambda x: x\n",
    "        from_space = lambda x: np.clip(x, 0, 1)\n",
    "    elif space == \"dct\":\n",
    "        to_space = lambda x: apply_channelwise(x, dct2d)\n",
    "        from_space = lambda x: np.clip(apply_channelwise(x, idct2d), 0, 1)\n",
    "    elif space == \"fft\":\n",
    "        to_space = lambda x: apply_channelwise(x, fft2d)\n",
    "        from_space = lambda x: np.clip(apply_channelwise(x, ifft2d), 0, 1)\n",
    "\n",
    "    # Transform to working domain\n",
    "    working_data = to_space(x_np)\n",
    "    working_flat = working_data.flatten()\n",
    "    n_dims = working_flat.shape[0]\n",
    "    perm = torch.randperm(n_dims)\n",
    "\n",
    "    # Benign output\n",
    "    with torch.no_grad():\n",
    "        benign_out = model.get_embeddings(x_tensor)\n",
    "        if isinstance(benign_out, torch.Tensor):\n",
    "            benign_out = benign_out.cpu().numpy()\n",
    "\n",
    "    # Initialize score\n",
    "    if metric == \"kl\":\n",
    "        benign_logits = benign_out  # store raw logits for p\n",
    "        current_score = compute_kl_from_logits(benign_logits, benign_logits, T)  # should be 0\n",
    "    else:\n",
    "        benign_embed = benign_out\n",
    "        current_score = 0.0\n",
    "\n",
    "    # Main loop\n",
    "    for i in range(num_iters):\n",
    "        idx = perm[i % n_dims].item()\n",
    "\n",
    "        # Create plus & minus candidates\n",
    "        candidates = []\n",
    "        for direction in [+1, -1]:\n",
    "            mod_flat = working_flat.copy()\n",
    "            mod_flat[idx] += direction * step_size\n",
    "\n",
    "            if space == \"image\":\n",
    "                mod_flat = np.clip(mod_flat, 0, 1)\n",
    "            elif space in [\"dct\", \"fft\"]:\n",
    "                mod_flat[idx] = np.clip(mod_flat[idx], -epsilon, epsilon)\n",
    "\n",
    "            mod_img = mod_flat.reshape(C, H, W)\n",
    "            img_reconstructed = from_space(mod_img)\n",
    "            candidates.append(torch.tensor(img_reconstructed, dtype=x_tensor.dtype, device=device).unsqueeze(0))\n",
    "            \n",
    "        # Forward pass for both candidates\n",
    "        with torch.no_grad():\n",
    "            outs = model.get_embeddings(torch.cat(candidates, dim=0))\n",
    "            if isinstance(outs, torch.Tensor):\n",
    "                outs = outs.cpu().numpy()\n",
    "\n",
    "        # Compute scores\n",
    "        if metric == \"kl\":\n",
    "            scores = [compute_kl_from_logits(benign_logits, o, T) for o in outs]\n",
    "        else:\n",
    "            scores = [np.linalg.norm(benign_embed - o) for o in outs]\n",
    "\n",
    "        # Accept change\n",
    "        if maximize:\n",
    "            better = np.argmax(scores)\n",
    "            if scores[better] > z:\n",
    "                working_flat[idx] += (+1 if better == 0 else -1) * step_size\n",
    "                current_score = scores[better]\n",
    "        else:\n",
    "            better = np.argmin(scores)\n",
    "            if scores[better] < current_score:\n",
    "                working_flat[idx] += (+1 if better == 0 else -1) * step_size\n",
    "                current_score = scores[better]\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"[{i+1}/{num_iters}] Score: {current_score:.4f}\")\n",
    "\n",
    "    # Final adversarial image\n",
    "    final_img = from_space(working_flat.reshape(C, H, W))\n",
    "    final_tensor = torch.tensor(final_img, dtype=x_tensor.dtype, device=device)\n",
    "    save_adv_batch(final_tensor, pth=pth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bc8a151f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n",
      "[180/200] Score: 0.0000\n",
      "[190/200] Score: 0.0000\n",
      "[200/200] Score: 0.0000\n",
      "[10/200] Score: 0.0000\n",
      "[20/200] Score: 0.0000\n",
      "[30/200] Score: 0.0000\n",
      "[40/200] Score: 0.0000\n",
      "[50/200] Score: 0.0000\n",
      "[60/200] Score: 0.0000\n",
      "[70/200] Score: 0.0000\n",
      "[80/200] Score: 0.0000\n",
      "[90/200] Score: 0.0000\n",
      "[100/200] Score: 0.0000\n",
      "[110/200] Score: 0.0000\n",
      "[120/200] Score: 0.0000\n",
      "[130/200] Score: 0.0000\n",
      "[140/200] Score: 0.0000\n",
      "[150/200] Score: 0.0000\n",
      "[160/200] Score: 0.0000\n",
      "[170/200] Score: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m im_batch \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43msimba_attack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mim_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 'kl' for asymmetric KL, 'l2' for L2 norm\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 'image', 'dct', or 'fft'\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 131\u001b[0m, in \u001b[0;36msimba_attack\u001b[0;34m(x_tensor, model, num_iters, epsilon, step_size, T, metric, space, maximize, device)\u001b[0m\n\u001b[1;32m    129\u001b[0m     outs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_embeddings(torch\u001b[38;5;241m.\u001b[39mcat(candidates, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outs, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 131\u001b[0m         outs \u001b[38;5;241m=\u001b[39m \u001b[43mouts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Compute scores\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for im_batch in loader:\n",
    "    simba_attack(\n",
    "        x_tensor=im_batch,\n",
    "        model=vit,\n",
    "        num_iters=200,\n",
    "        epsilon=1/255,\n",
    "        step_size=1e-5,\n",
    "        T=1.0,\n",
    "        metric=\"kl\",       # 'kl' for asymmetric KL, 'l2' for L2 norm\n",
    "        space=\"image\",       # 'image', 'dct', or 'fft'\n",
    "        maximize=True,\n",
    "        device=\"cuda\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
